{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus: \n",
    "    tf.config.set_logical_device_configuration(gpus[0], [tf.config.LogicalDeviceConfiguration(memory_limit=5292)])\n",
    "\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras import layers, optimizers, losses, metrics, Model\n",
    "from PIL import Image\n",
    "from sklearn import preprocessing as pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the discriminator.\n",
    "def create_D():\n",
    "    input_img = keras.Input(shape=(256,256, 1))\n",
    "\n",
    "    conv1 = layers.Conv2D(8, (2,2), (2,2), padding='valid', \n",
    "                                activation=layers.ReLU())(input_img)\n",
    "    drop1 = layers.Dropout(rate=0.5)(conv1)\n",
    "\n",
    "    down1 = layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding=\"valid\")(drop1)\n",
    "\n",
    "    flat1 = layers.Flatten()(down1)\n",
    "\n",
    "    score = layers.Dense(1, activation='sigmoid')(flat1)\n",
    "\n",
    "    D: Model = Model(inputs=input_img, outputs=score)\n",
    "    D.compile(optimizer=optimizers.Nadam(learning_rate=0.002), loss=losses.BinaryCrossentropy(), metrics=metrics.MeanAbsoluteError())\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the generator.\n",
    "def create_G():\n",
    "    random_input = keras.Input(shape=(100, ))\n",
    "\n",
    "    Dense1 = layers.Dense(units = 16*16)(random_input)\n",
    "\n",
    "    B_Norm1 = layers.BatchNormalization()(Dense1)\n",
    "\n",
    "    Relu1 = layers.LeakyReLU()(B_Norm1)\n",
    "\n",
    "    reshape1 = layers.Reshape(target_shape=(16, 16, 1))(Relu1)\n",
    "\n",
    "    DeConv1 = layers.Conv2DTranspose(filters=4, kernel_size=(2, 2), strides=(1,1), padding='same')(reshape1)\n",
    "\n",
    "    B_Norm2 = layers.BatchNormalization()(DeConv1)\n",
    "\n",
    "    Relu2 = layers.LeakyReLU()(B_Norm2)\n",
    "\n",
    "    DeConv2 = layers.Conv2DTranspose(filters=16, kernel_size=(3,3), strides=(1,1), padding='same')(Relu2)\n",
    "\n",
    "    re = layers.Reshape((16,16,16,1))(DeConv2)\n",
    "\n",
    "    maxi0 = layers.MaxPool3D(pool_size=(4,4,2))(re)\n",
    "\n",
    "    B_Norm3 = layers.BatchNormalization()(maxi0)\n",
    "\n",
    "    Relu3 = layers.LeakyReLU()(B_Norm3)\n",
    "\n",
    "    flat0 = layers.Flatten()(Relu3)\n",
    "\n",
    "    dense00 = layers.Dense(units=256*256, activation='tanh')(flat0)\n",
    "\n",
    "    output_img = layers.Reshape((256, 256, 1))(dense00)\n",
    "\n",
    "    G = Model(inputs=random_input, outputs=output_img)\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the discriminator and generator, forming the final GAN model.\n",
    "def create_GAN():\n",
    "    D = create_D() \n",
    "    G = create_G()\n",
    "    latent_input = keras.Input(shape=(100, ))\n",
    "    img = G(latent_input)\n",
    "    D.trainable = False\n",
    "    score = D(img)\n",
    "    GAN = Model(inputs = latent_input, outputs=score)\n",
    "    GAN.compile(loss=losses.BinaryCrossentropy(),  \n",
    "            optimizer=optimizers.Nadam(learning_rate=0.002), metrics=metrics.MeanAbsoluteError())\n",
    "    return D, G, GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function returns a sample of latent points from a normal distribution.\n",
    "def getLatentSamples(num_samples) -> np.ndarray:\n",
    "    latent = np.random.normal(size=100*int(num_samples))\n",
    "    latent = np.reshape(a=latent, newshape=(int(num_samples), 100))\n",
    "    return latent\n",
    "\n",
    " \n",
    "# Function imputs latent data into the generator and returns the fake image samples outputted \n",
    "# by the generator.\n",
    "def getRealSamples(batch_size: int, train_img: np.ndarray):\n",
    "    X_real, y_real = np.array(train_img.tolist() * batch_size, dtype=np.float32).reshape((batch_size, train_img.shape[0], train_img.shape[1])), np.ones(shape=batch_size, dtype=np.int8)\n",
    "    assert X_real.shape == (batch_size, train_img.shape[0], train_img.shape[1])\n",
    "    assert y_real.shape == (batch_size, )\n",
    "    return X_real, y_real\n",
    "\n",
    "# Function imputs latent data into the generator and returns the fake image samples outputted \n",
    "# by the generator.\n",
    "def getFakeSamples(G:Model, batch_size:int):\n",
    "    latent = getLatentSamples(batch_size)\n",
    "    assert latent.shape == (batch_size, 100)\n",
    "    fake_imgs = G(latent)\n",
    "    fake_imgs = np.asarray(fake_imgs, dtype=np.float32)\n",
    "    assert fake_imgs.shape[0] == batch_size\n",
    "    fake_imgs = np.squeeze(fake_imgs)\n",
    "    output_labels = np.zeros(shape=batch_size, dtype=np.int8)\n",
    "    assert output_labels.shape == (batch_size, )\n",
    "    return fake_imgs, output_labels   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function plots a sample of 16 'predicted' images from the trained generator.\n",
    "def pred_plot(G: Model, epoch:int, train_img_shape: tuple[int, int]):\n",
    "    shape = train_img_shape\n",
    "    latent = getLatentSamples(1)\n",
    "    gen_image = G(latent)\n",
    "    gen_image = np.asarray(gen_image, dtype=np.float32)\n",
    "    gen_image = np.squeeze(gen_image)\n",
    "    assert gen_image.shape == shape\n",
    "    filename = str('images/gen3-%d.png' %epoch)\n",
    "    plt.imsave(filename, gen_image, cmap='gray')\n",
    "    if epoch % 100 == 0:\n",
    "        im=Image.open(filename)\n",
    "        im.load()\n",
    "        im.convert('L').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function trains the GAN (generator) model.\n",
    "def trainGAN(D:Model, G:Model, GAN:Model, num_epochs: int, batchSize: int, train_img: np.ndarray, train_img_shape: tuple[int, int]):\n",
    "    d_loss, g_loss = [], []\n",
    "    d_mae, g_mae = [], []\n",
    "    pred_plot(G, 0, train_img_shape)\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        X_real, y_real = getRealSamples(int(batchSize/2), train_img)\n",
    "        X_fake, y_fake = getFakeSamples(G, int(batchSize / 2))\n",
    "        assert X_real.shape == X_fake.shape\n",
    "        assert X_real.shape[0] == int(batchSize / 2)\n",
    "        assert y_real.shape == y_fake.shape\n",
    "        assert y_real.shape[0] == int(batchSize / 2)\n",
    "        D.trainable = True\n",
    "        d_loss_fake, mae_fake = D.train_on_batch(X_fake, y_fake)\n",
    "        d_loss_real, mae_real = D.train_on_batch(X_real, y_real)\n",
    "        D.trainable = False\n",
    "        X_latent, y_latent = getLatentSamples(batchSize), np.ones(shape=batchSize, dtype=np.int8)\n",
    "        loss, mae = GAN.train_on_batch(X_latent, y_latent)\n",
    "\n",
    "        d_loss_res = float((d_loss_fake + d_loss_real) / 2)\n",
    "        d_mae_res = float((mae_fake + mae_real) / 2)\n",
    "        d_loss.append(d_loss_res)\n",
    "        d_mae.append(d_mae_res)\n",
    "        g_loss.append(loss)\n",
    "        g_mae.append(mae)\n",
    "        if (epoch % 50 == 0) and epoch != 0:\n",
    "            pred_plot(G, epoch, train_img_shape)\n",
    "            models = (D, G, GAN)\n",
    "            filepaths = ('D_final.h5', 'G_final.h5', 'GAN_final.h5')\n",
    "            for model, name in zip(models, filepaths):\n",
    "                model.save(name)\n",
    "            print('Epoch: %d\\nDiscriminator Loss: %.3f, Generator Loss: %.3f\\nDiscriminator MAE: %.3f, Generator MAE: %.3f' % (epoch, d_loss[-1], g_loss[-1], d_mae[-1], g_mae[-1]))\n",
    "            \n",
    "    fig, ax = plt.subplots(2,2, figsize=(11,11))\n",
    "    ax[0][0].plot(list(range(len(d_loss))), d_loss, label='D_loss', color='red', linestyle='dashed', linewidth=1)\n",
    "    ax[0][1].plot(list(range(len(g_loss))), g_loss, label='G_loss', color='red', linestyle='solid', linewidth=1)\n",
    "    ax[1][0].plot(list(range(len(d_mae))), d_mae, label='D_mae', color='blue', linestyle='dashed', linewidth=1)\n",
    "    ax[1][1].plot(list(range(len(g_mae))), g_mae, label='G_mae', color='blue', linestyle='solid', linewidth=1)\n",
    "    fig.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"loss_plots\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = Image.open(\"orig_img_color.png\")\n",
    "img.load()\n",
    "img = img.convert(mode='RGB').convert(mode='L')\n",
    "img = np.asarray(img, dtype=np.float32)\n",
    "try:\n",
    "    assert img.shape == (256, 256)\n",
    "except:\n",
    "    img = np.reshape(a=img, newshape=(256, 256))\n",
    "training_img = pre.minmax_scale(img.flatten(), (-1,1))\n",
    "training_img = training_img.reshape(img.shape)\n",
    "    \n",
    "D, G, GAN = create_GAN()\n",
    "\n",
    "def show_summary(D, G, GAN):\n",
    "    D.summary() \n",
    "    G.summary()\n",
    "    GAN.summary()\n",
    "\n",
    "verbose = input('Enter T/F for verbose output: ')\n",
    "if verbose == 'T':\n",
    "    show_summary(D, G, GAN)   \n",
    "    \n",
    "trainGAN(D, G, GAN, 10000, 16, training_img, training_img.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8db45bb5f299d65e64b609bd5b49ed00a0c39035b13f03eb9cc2c5035708e4ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
